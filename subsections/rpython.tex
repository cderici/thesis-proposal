\subsection{Tracing JITs \& RPython Framework}
\label{subsec:rpython}

JIT compilers allow programs to be compiled dynamically at run-time
during the evaluation via an interpreter. As opposed to the
ahead-of-time (AOT) compilers, JITs interleave the compilation with
execution, aiming to compile and optimize only the parts of the
program that are used the most. JIT compilers employ a low-overhead
profiling to dynamically detect a frequent (i.e. hot) sequence of
instructions during interpretation. Starting with evaluating a given
program with an interpreter, a JIT compiler stops the evaluation when
a frequently evaluated instruction path is detected, compiles the
instructions and starts using the compiled path whenever the same path
needs to be evaluated again. [CITE?]

  \begin{wrapfigure}[21]{r}{0.35\textwidth}
    \vspace{-0.5cm}
    \centering
    \begin{minipage}[t]{0.32\textwidth}
      \begin{minted}[numbersep=0pt,gobble=0,linenos,numbers=right,fontsize=\scriptsize,frame=lines]{python}
# start of the trace (outer loop)
label(p0, p1, descr="64723312")
guard_not_invalidated()
guard_class(p0, ConsEnv)
p3 = getfield_gc_r(p0, descr="ConsEnv.prev")
guard_class(p3, ConsEnv)
i5 = getfield_gc_i(p3, descr="Fixnum")
i6 = getfield_gc_i(p0, descr="Fixnum")
i7 = int_add_ovf(i5, i6)
guard_no_overflow()
guard_class(p1, LetCont)
p9 = getfield_gc_r(p1, descr="LetCont.ast")
guard_value(p9, ConstPtr(ptr10))
p11 = getfield_gc_r(p1, descr="LetCont.env")
p12 = getfield_gc_r(p1, descr="LetCont.prev")
# inner loop
label(p11, i7, p12, descr="64723392")
guard_not_invalidated()
guard_class(p11, ConsEnv)
i14 = getfield_gc_i(p11, descr="Fixnum")
i15 = int_add_ovf(i14, i7)
guard_no_overflow()
guard_class(p12, LetCont)
p17 = getfield_gc_r(p12, descr="LetCont.ast")
guard_value(p17, ConstPtr(ptr18))
p19 = getfield_gc_r(p12, descr="LetCont.env")
p20 = getfield_gc_r(p12, descr="LetCont.prev")
# jump
jump(p19, i15, p20, descr="64723392")

    \end{minted}
    \end{minipage}
    \caption{\small Example trace}
    \label{fig:trace}
  \end{wrapfigure}

JITs have been shown to be significantly effective in VM
implementations for dynamic languages [CITE]. There are two main
approaches in JIT compilation. Method-based compilation work on the
method level, and compile the most frequently used methods in the
program [CITE], while trace-based JIT compilers compile the most
frequently evaluated loops [CITE]. In this thesis, we're interested in
the trace-based JIT compilation, as we work with meta-tracing,

Trace-based JIT compilation works on two principal assumptions:

\textbf{i)} Programs spend most of their running time in loops.

\textbf{ii)} Several iterations of the same loop are likely to take
similar code paths.

To exploit these assumptions, a tracing JIT classifies certain
execution paths to be \emph{hot loops} during the evaluation. When a
hot loop is detected, as described before the evaluation stops, and
loop is compiled and optimized into a \emph{trace}, and then the
execution continues, using the compiled trace whenever the same path
needs to be executed. A trace is a linear sequence of instructions
with an entry point and one or more exit points. \figref{fig:trace}
shows a simplified example of a typical trace, taking two arguments
$p0$ and $p1$ as inputs, having a preamble (because of unrolling) and
an inner loop that jumps to itself. The \emph{guards} within a trace
make up the trace's exit points, where the trace jumps out if certain
conditions are not satisfied. They are often used for \textbf{i)}
making sure in the preamble the conditions are the same when this
sequence is first traced, and \textbf{ii)} to finish and exit the
loop.

  \begin{wrapfigure}[21]{r}{0.35\textwidth}
    \vspace{-0.5cm}
    \centering
    \begin{minipage}[t]{0.32\textwidth}
      \begin{minted}[numbersep=0pt,gobble=0,linenos,numbers=right,fontsize=\scriptsize,frame=lines]{python}
driver = JitDriver(greens = ['pc', 'bytecode'],
                   reds   = ['a', 'regs'])

def interpret(bcode, a):
  regs = [0] * 256
  pc = 0

  while True:
    driver.jit_merge_point(bcode=bytecode,
                          pc=pc,a=a,
                          regs=regs)
    opcode = ord(bytecode[pc])
    pc += 1

    if opcode == JUMP_IF_A:
      target = ord(bcode[pc])
      pc += 1
      if a:
        if target < pc:
          driver.can_enter_jit(bytecode=bcode,
                              pc=target,
                              a=a, regs=regs)
        pc = target
    elif opcode == MOV_A_R:
      ...
    \end{minted}
    \end{minipage}
    \caption{\small An interpreter annotated with hints \cite{bolz09}}
    \label{fig:rpython-interp}
  \end{wrapfigure}

\paragraph{Meta-tracing}
Just like evaluating a regular program, evaluating for example a
byte-code interpreter for a language on a tracing JIT naturally forms
an implementation of the language. However, the loops that are traced
during the execuion of the interpreter not necessarily correspond to
the loops implemented in the user program that is being
interpreted. In particular, since a byte-code interpreter is basically
a dispatch loop for the byte-code instructions in the language, a
trace of an execution path within such an interpretation loop consists
of instructions implementing only one particular byte-code. However,
it is rarely the case where a single byte-code is repeatedly executed
when evaluating a program on an interpreter. Additionally the loops in
the user program, in which most of the running time will be spent are
never being traced. Therefore this approach leads to compiling traces
that most likely will be used only once at a time (exit out at the end
of the trace, as the next byte-code will not be the same),
resulting in a worse performance than even just interpreting.

Meta-tracing introduces certain hints and annotations for the tracer
to be utilized within the executed program (in our case the
interpreter) to capture the useful traces that will be executed
repeatedly, e.g. in the case of an interpreter the ones that will
correspond to the loops in the user program. The loop detection is
simply finding a spot where the program jumped
backwards. \figref{fig:rpython-interp} shows an example interpreter
decorated with such annotations and hints. The annotations allow the
implementer to set the parameters (\emph{greens}) that constitute what
can be considered as a compund program counter (pc), by which the
tracer will detect that the program jumped backwards. Additionally the
hints allow the points where the program might jump backwards to be
stated.  The reader is referred to \cite{bolz09} for a detailed
discussion.

RPython framework


Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works.

Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works.

Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works. Here's how RPython and meta-tracing works.
